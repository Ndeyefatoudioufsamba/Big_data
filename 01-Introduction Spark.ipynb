{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Introduction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Rappel :Big Data 4 Vs\n",
    "\n",
    "<div style=\"text-align:center\"><img src=\"images/4V.png\" /></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Apache Hadoop \n",
    "* 2003, Google développe le système fichier distribué tolerant au pannes appelé **Google File System (GFS)**\n",
    "* 2004, Google propose **Map Reduce (MR)** pour traiter les données stocké dans un cluster **Google File System (GFS)**\n",
    "* 2006, Yahoo implemente le framework open-source **Hadoop** basée sur **MR** et **Hadoop Distributed File System (HDFS)**  \n",
    "* Aujourd'hui, Hadoop ecosyteme est un ensemble de modules et/ou logiciels open-source permettant de traiter, d'analyse de données massive (Big Data): HDFS, Yarn, MapReduce, Pig, Hive, HBASE, Zookeeper, etc.  \n",
    "<div style=\"text-align:center\"><img src=\"images/hadoop.png\" /></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Hadoop Ecosystème\n",
    "\n",
    "* Ingestion des données (Flume, Sqoop, Kafka, NIFI)\n",
    "* Stockage des données (HDFS, HBase, Kudu)\n",
    "* Processing (Hadoop MapReduce, Pig)\n",
    "* Manipulation des données comme des tables SQL (Impala, Hive)\n",
    "* Exploration des données (Hue, Ambari)\n",
    "* Protection des données (Apache Sentry, Apache Ranger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# HDFS Architecture\n",
    "![](./images/hdfs.png)\n",
    "\n",
    "**Note** : MR envoie le ***mappeur*** et le ***reduceur*** vers le cluster où se trouvent les données plutôt d'apporter les données vers l'application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Accès aux données\n",
    "\n",
    "<div style=\"text-align:center\"><img src=\"images/motiv.png\" /></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Opérations I/O de Hadoop/MR\n",
    "* Itération intermittente de lectures et d'écritures entre ***mappeur*** et le ***reduceur***\n",
    "* Les gros jobs MR peuvent durer des heures, voire des jours.  \n",
    "\n",
    "\n",
    "<div style=\"text-align:center\"><img src=\"images/mr_jobs.png\" /></div>\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Apache Spark \n",
    "\n",
    "* Débuter comme projet de recherche à l'UC Berkeley en 2009\n",
    "* Licence Open Source (Apache 2.0)\n",
    "* Latest Stable Release: 3.4.0 (Mai 2023)\n",
    "* Plus de 800,000 lines de code (66% Scala)\n",
    "* Built by 1500+ developers from 200+ companies \n",
    "* Interfaçage avec Scala, Python, R et Java\n",
    "\n",
    "![](./images/sparklogo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Hadoop vs Spark : \n",
    "![](./images/inmemory.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Spark sources de données\n",
    "![](./images/sparksources.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Spark Architecture\n",
    "Nous avons cinq élements essentiels dans les étapes d'execution d'un job Spark :  \n",
    "\n",
    "* Spark Driver\n",
    "* SparkSession\n",
    "* Cluster Menager\n",
    "* Spark executor\n",
    "* Deployment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](./images/sparkArchitecture.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Spark Driver : \n",
    "\n",
    "* **Spark Application** est responsable de l'instanciation d'une **SparkSession**, \n",
    "* **Spark Driver** a plusieurs rôles: \n",
    "    * communique avec le gestionnaire de cluster; \n",
    "    * demande des ressources (CPU, mémoire, etc.) au gestionnaire de cluster pour les exécuteurs de Spark (JVM);\n",
    "    * transforme toutes les opérations Spark en calculs DAG, planifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# SparkSession\n",
    "* **SparkSession** est devenu un canal unifié vers toutes les opérations et données Spark.\n",
    "* Elle est le point d'entrèe de spark par l'intermediaire de **SparkContext**, **SQLContext**, **HiveContext**, **SparkConf** ou **StreamingContext**\n",
    "\n",
    "```// In Scala\n",
    "import org.apache.spark.sql.SparkSession\n",
    "// Build SparkSession\n",
    "val spark = SparkSession\n",
    ".builder\n",
    ".appName(\"LearnSpark\")\n",
    ".config(\"spark.sql.shuffle.partitions\", 6)\n",
    ".getOrCreate()\n",
    "...\n",
    "// Use the session to read JSON\n",
    "val people = spark.read.json(\"...\")\n",
    "...\n",
    "// Use the session to issue a SQL query\n",
    "val resultsDF = spark.sql(\"SELECT city, pop, state, zip FROM table_name\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Cluster Manager\n",
    "* **Cluster Manager** est responsable de la gestion et de l'allocation des ressources pour le cluster dans lequel l'application Spark s'exécute. \n",
    "* Spark prend en charge, pour le moment, quatre cluster managers: \n",
    "    * Standalone (gestionaire autonome intégré), \n",
    "    * Apache Hadoop YARN, \n",
    "    * Apache Mesos \n",
    "    * Kubernetes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Spark executor\n",
    "\n",
    "* Un exécuteur Spark s'exécute sur chaque worker node du cluster.\n",
    "* Les exécuteurs communiquent avec le Driver et sont responsables de l'exécution des tâches sur les worker nodes.\n",
    "* Dans plusieurs modes de déploiement, un seul exécuteur s'exécute par nœud."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Spark Deployment : Standalone\n",
    "\n",
    "![](./images/standalone.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "**Explication**\n",
    "\n",
    "Spark Standalone utilise un ordonnaceur (scheduler) intégré sans dépendre d'un scheduler externe tel que YARN ou Mesos. Pour installer Spark en mode Standalone, vous devez copier le package d'installation binaire Spark sur toutes les machines du cluster. En mode Standalone, le client peut interagir avec le cluster, soit via Spark-submit ou Spark Shell. Dans les deux cas, le Driver communique avec le Master node de Spark pour obtenir les Worker nodes, où les exécuteurs peuvent être démarrés pour cette application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Spark Deployment : Yarn\n",
    "Il existe deux methodes de deploiment avec YARN scheduler :\n",
    "\n",
    "* Connexion sur un cluster YARN en mode client:  \n",
    "``./bin/spark-shell --master yarn --deploy-mode client``   \n",
    "* Connexion sur un cluster YARN en mode cluster:  \n",
    "``./bin/spark-shell --master yarn --deploy-mode cluster``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Yarn Client Mode\n",
    "\n",
    "![](./images/yarn-client-mode.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "**Explication**  \n",
    "En mode client YARN, le Driver s'exécute sur un nœud en dehors du cluster (généralement là où se trouve le client). Le Driver contacte d'abord le gestionnaire de ressources pour demander des ressources pour exécuter un job Spark. Le gestionnaire de ressources alloue un conteneur (conteneur zéro) et répond au Driver. Le Driver lance ensuite l'application Spark Master dans le conteneur zéro. L'application Master de Spark crée ensuite les exécuteurs sur les conteneurs alloués par le gestionnaire de ressources. Les conteneurs YARN peuvent être sur n'importe quel nœud du cluster contrôlé par le node manager. Ainsi, toutes les allocations sont gérées par le gestionnaire de ressources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Yarn Cluster mode\n",
    "![](./images/yarn-cluster-mode.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "**Explication**\n",
    "\n",
    "En mode cluster YARN, le Driver s'exécute sur un nœud à l'intérieur du cluster (généralement là où se trouve l'application Master). Le client contacte d'abord le *Resource Manager* pour demander des ressources pour exécuter le job Spark. Le *Resource Manager* alloue un conteneur (conteneur zéro) et répond au client. Le client soumet ensuite le code au cluster, puis lance le Driver et l'application Master de Spark dans le conteneur zéro. Le pilote s'exécute avec le maître d'application et le maître d'application Spark, puis crée les exécuteurs sur les conteneurs alloués par le gestionnaire de ressources. Les conteneurs YARN peuvent se trouver sur n'importe quel nœud du cluster contrôlé par le *node manager*. Ainsi, toutes les allocations sont gérées par le *Resource Manager*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Spark deploiement : Mesos\n",
    "\n",
    "![](./images/mesos-cluster-mode.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "**Explication**\n",
    "\n",
    "Le déploiement de Mesos est similaire au mode Standalonde de Spark. L Driver communique avec le Mesos Master, qui alloue ensuite les ressources nécessaires pour exécuter les exécuteurs. Comme vu en mode Standalone, le Driver communique ensuite avec les exécuteurs pour exécuter le job. Ainsi, le Driver, sur le premier deploiement dans Mesos, communique d'abord avec le  Master, puis sécurise la demande du conteneur sur tous les nœuds slaves de Mesos.  \n",
    "Lorsque les conteneurs sont alloués au job Spark, le Driver démarre les exécuteurs, puis exécute le code dans les exécuteurs. Lorsque le job Spark est terminé et que le Driver se termine, le nœud Master de Mesos est averti, ainsi toutes les ressources allouées sous forme de conteneurs dans les nœuds esclaves Mesos vont etre récupérées.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plan d'execution de Spark \n",
    "\n",
    "### Etape d'exécution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/adb-plans-flow-execution-process.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimiseur Catalyst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/adb-plans-flow-catalyst-optimizer.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Démo d'installation de Apache Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plus de détails voir README.md\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "rise": {
   "height": "90%",
   "width": "90%"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
